{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProjectCode-873.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOY9XQhruLw9qZjWu96CNzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlita604/bug-free-eureka/blob/main/FinalProjectCode_873.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
        "#Part 1: Vanilla Implementation (from scratch) \n",
        "#⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡"
      ],
      "metadata": {
        "id": "l6ccTonbqzJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BFV Implementation from Scratch"
      ],
      "metadata": {
        "id": "oTyk-0-IpBSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.polynomial import polynomial as poly\n",
        "\n",
        "def polymul(x, y, modulus, poly_mod):\n",
        "    \"\"\"Add two polynoms\n",
        "    Args:\n",
        "        x, y: two polynoms to be added.\n",
        "        modulus: coefficient modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "    Returns:\n",
        "        A polynomial in Z_modulus[X]/(poly_mod).\n",
        "    \"\"\"\n",
        "    return np.int64(\n",
        "        np.round(poly.polydiv(poly.polymul(x, y) % modulus, poly_mod)[1] % modulus)\n",
        "    )\n",
        "\n",
        "\n",
        "def polyadd(x, y, modulus, poly_mod):\n",
        "    \"\"\"Multiply two polynoms\n",
        "    Args:\n",
        "        x, y: two polynoms to be multiplied.\n",
        "        modulus: coefficient modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "    Returns:\n",
        "        A polynomial in Z_modulus[X]/(poly_mod).\n",
        "    \"\"\"\n",
        "    return np.int64(\n",
        "        np.round(poly.polydiv(poly.polyadd(x, y) % modulus, poly_mod)[1] % modulus)\n",
        "    )\n",
        "\n",
        "def gen_binary_poly(size):\n",
        "    \"\"\"Generates a polynomial with coeffecients in [0, 1]\n",
        "    Args:\n",
        "        size: number of coeffcients, size-1 being the degree of the\n",
        "            polynomial.\n",
        "    Returns:\n",
        "        array of coefficients with the coeff[i] being \n",
        "        the coeff of x ^ i.\n",
        "    \"\"\"\n",
        "    return np.random.randint(0, 2, size, dtype=np.int64)\n",
        "\n",
        "\n",
        "def gen_uniform_poly(size, modulus):\n",
        "    \"\"\"Generates a polynomial with coeffecients being integers in Z_modulus\n",
        "    Args:\n",
        "        size: number of coeffcients, size-1 being the degree of the\n",
        "            polynomial.\n",
        "    Returns:\n",
        "        array of coefficients with the coeff[i] being \n",
        "        the coeff of x ^ i.\n",
        "    \"\"\"\n",
        "    return np.random.randint(0, modulus, size, dtype=np.int64)\n",
        "\n",
        "\n",
        "def gen_normal_poly(size):\n",
        "    \"\"\"Generates a polynomial with coeffecients in a normal distribution\n",
        "    of mean 0 and a standard deviation of 2, then discretize it.\n",
        "    Args:\n",
        "        size: number of coeffcients, size-1 being the degree of the\n",
        "            polynomial.\n",
        "    Returns:\n",
        "        array of coefficients with the coeff[i] being \n",
        "        the coeff of x ^ i.\n",
        "    \"\"\"\n",
        "    return np.int64(np.random.normal(0, 2, size=size))\n",
        "\n",
        "def keygen(size, modulus, poly_mod):\n",
        "    \"\"\"Generate a public and secret keys\n",
        "    Args:\n",
        "        size: size of the polynoms for the public and secret keys.\n",
        "        modulus: coefficient modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "    Returns:\n",
        "        Public and secret key.\n",
        "    \"\"\"\n",
        "    sk = gen_binary_poly(size)\n",
        "    a = gen_uniform_poly(size, modulus)\n",
        "    e = gen_normal_poly(size)\n",
        "    b = polyadd(polymul(-a, sk, modulus, poly_mod), -e, modulus, poly_mod)\n",
        "    return (b, a), sk"
      ],
      "metadata": {
        "id": "yhjQDFRUl0F1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Ecryption \"\"\"\n",
        "def encrypt(pk, size, q, t, poly_mod, pt):\n",
        "    \"\"\"Encrypt an integer.\n",
        "    Args:\n",
        "        pk: public-key.\n",
        "        size: size of polynomials.\n",
        "        q: ciphertext modulus.\n",
        "        t: plaintext modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "        pt: integer to be encrypted.\n",
        "    Returns:\n",
        "        Tuple representing a ciphertext.      \n",
        "    \"\"\"\n",
        "    # encode the integer into a plaintext polynomial\n",
        "    m = np.array([pt] + [0] * (size - 1), dtype=np.int64) % t\n",
        "    delta = q // t\n",
        "    scaled_m = delta * m  % q\n",
        "    e1 = gen_normal_poly(size)\n",
        "    e2 = gen_normal_poly(size)\n",
        "    u = gen_binary_poly(size)\n",
        "    ct0 = polyadd(\n",
        "            polyadd(\n",
        "                polymul(pk[0], u, q, poly_mod),\n",
        "                e1, q, poly_mod),\n",
        "            scaled_m, q, poly_mod\n",
        "        )\n",
        "    ct1 = polyadd(\n",
        "            polymul(pk[1], u, q, poly_mod),\n",
        "            e2, q, poly_mod\n",
        "        )\n",
        "    return (ct0, ct1)"
      ],
      "metadata": {
        "id": "jINxwES5pTVT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Decryption\"\"\"\n",
        "def d(sk, size, q, t, poly_mod, ct):\n",
        "    \"\"\"Decrypt a ciphertext\n",
        "    Args:\n",
        "        sk: secret-key.\n",
        "        size: size of polynomials.\n",
        "        q: ciphertext modulus.\n",
        "        t: plaintext modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "        ct: ciphertext.\n",
        "    Returns:\n",
        "        Integer representing the plaintext.\n",
        "    \"\"\"\n",
        "    scaled_pt = polyadd(\n",
        "            polymul(ct[1], sk, q, poly_mod),\n",
        "            ct[0], q, poly_mod\n",
        "        )\n",
        "    decrypted_poly = np.round(scaled_pt * t / q) % t\n",
        "    return int(decrypted_poly[0])"
      ],
      "metadata": {
        "id": "2XAgfuqqpX3K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Addition and Multiplication Method Implementation\"\"\"\n",
        "\n",
        "def add_plain(ct, pt, q, t, poly_mod):\n",
        "    \"\"\"Add a ciphertext and a plaintext.\n",
        "    Args:\n",
        "        ct: ciphertext.\n",
        "        pt: integer to add.\n",
        "        q: ciphertext modulus.\n",
        "        t: plaintext modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "    Returns:\n",
        "        Tuple representing a ciphertext.\n",
        "    \"\"\"\n",
        "    size = len(poly_mod) - 1\n",
        "    # encode the integer into a plaintext polynomial\n",
        "    m = np.array([pt] + [0] * (size - 1), dtype=np.int64) % t\n",
        "    delta = q // t\n",
        "    scaled_m = delta * m  % q\n",
        "    new_ct0 = polyadd(ct[0], scaled_m, q, poly_mod)\n",
        "    return (new_ct0, ct[1])\n",
        "\n",
        "def mul_plain(ct, pt, q, t, poly_mod):\n",
        "    \"\"\"Multiply a ciphertext and a plaintext.\n",
        "    Args:\n",
        "        ct: ciphertext.\n",
        "        pt: integer to multiply.\n",
        "        q: ciphertext modulus.\n",
        "        t: plaintext modulus.\n",
        "        poly_mod: polynomial modulus.\n",
        "    Returns:\n",
        "        Tuple representing a ciphertext.\n",
        "    \"\"\"\n",
        "    size = len(poly_mod) - 1\n",
        "    # encode the integer into a plaintext polynomial\n",
        "    m = np.array([pt] + [0] * (size - 1), dtype=np.int64) % t\n",
        "    new_c0 = polymul(ct[0], m, q, poly_mod)\n",
        "    new_c1 = polymul(ct[1], m, q, poly_mod)\n",
        "    return (new_c0, new_c1)"
      ],
      "metadata": {
        "id": "MFUH_D7xpoEQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CKKS Implementation from Scratch\n"
      ],
      "metadata": {
        "id": "XrZHHiVak2Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# First we set the parameters\n",
        "M = 8\n",
        "N = M //2\n",
        "\n",
        "# We set xi, which will be used in our computations\n",
        "xi = np.exp(2 * np.pi * 1j / M)\n",
        "xi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7icUfuk_tp",
        "outputId": "7fc9bdc0-ebce-4dcb-f882-156402d83f46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7071067811865476+0.7071067811865475j)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.polynomial import Polynomial\n",
        "\n",
        "class CKKSEncoder:\n",
        "    \"\"\"Basic CKKS encoder to encode complex vectors into polynomials.\"\"\"\n",
        "    \n",
        "    def __init__(self, M: int):\n",
        "        \"\"\"Initialization of the encoder for M a power of 2. \n",
        "        \n",
        "        xi, which is an M-th root of unity will, be used as a basis for our computations.\n",
        "        \"\"\"\n",
        "        self.xi = np.exp(2 * np.pi * 1j / M)\n",
        "        self.M = M\n",
        "        \n",
        "    @staticmethod\n",
        "    def vandermonde(xi: np.complex128, M: int) -> np.array:\n",
        "        \"\"\"Computes the Vandermonde matrix from a m-th root of unity.\"\"\"\n",
        "        \n",
        "        N = M //2\n",
        "        matrix = []\n",
        "        # We will generate each row of the matrix\n",
        "        for i in range(N):\n",
        "            # For each row we select a different root\n",
        "            root = xi ** (2 * i + 1)\n",
        "            row = []\n",
        "\n",
        "            # Then we store its powers\n",
        "            for j in range(N):\n",
        "                row.append(root ** j)\n",
        "            matrix.append(row)\n",
        "        return matrix\n",
        "    \n",
        "    def sigma_inverse(self, b: np.array) -> Polynomial:\n",
        "        \"\"\"Encodes the vector b in a polynomial using an M-th root of unity.\"\"\"\n",
        "\n",
        "        # First we create the Vandermonde matrix\n",
        "        A = CKKSEncoder.vandermonde(self.xi, M)\n",
        "\n",
        "        # Then we solve the system\n",
        "        coeffs = np.linalg.solve(A, b)\n",
        "\n",
        "        # Finally we output the polynomial\n",
        "        p = Polynomial(coeffs)\n",
        "        return p\n",
        "\n",
        "    def sigma(self, p: Polynomial) -> np.array:\n",
        "        \"\"\"Decodes a polynomial by applying it to the M-th roots of unity.\"\"\"\n",
        "\n",
        "        outputs = []\n",
        "        N = self.M //2\n",
        "\n",
        "        # We simply apply the polynomial on the roots\n",
        "        for i in range(N):\n",
        "            root = self.xi ** (2 * i + 1)\n",
        "            output = p(root)\n",
        "            outputs.append(output)\n",
        "        return np.array(outputs)"
      ],
      "metadata": {
        "id": "a3NL_ViDlJUZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Initialize Encoder and vector\"\"\"\n",
        "encoder = CKKSEncoder(M)\n",
        "b = np.array([1, 2, 3, 4])\n",
        "b\n",
        "\"\"\" Encode a vector with real values\"\"\"\n",
        "p = encoder.sigma_inverse(b)\n",
        "p\n",
        "\"\"\"Reconstruct the vector\"\"\"\n",
        "b_reconstructed = encoder.sigma(p)\n",
        "b_reconstructed\n",
        "\n",
        "\"\"\" Note the difference between the vectors\"\"\"\n",
        "np.linalg.norm(b_reconstructed - b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zLxKOn2lNCA",
        "outputId": "f6b13183-62e5-45fb-c488-eeccf6088283"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.944442800358888e-16"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CKKS TenSEAL Context"
      ],
      "metadata": {
        "id": "gqcA2DgknNN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from random import randint\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "from typing import Dict\n",
        "\n",
        "import tenseal as ts"
      ],
      "metadata": {
        "id": "Ko3Yti1qnQ6X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def context():\n",
        "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "    context.global_scale = pow(2, 40)\n",
        "    context.generate_galois_keys()\n",
        "    return context\n",
        "\n",
        "context = context()"
      ],
      "metadata": {
        "id": "dyDtqqy3nVDm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plain1 = ts.plain_tensor([1,2,3,4], [2,2])\n",
        "\n",
        "print(\" First tensor: Shape = {} Data = {}\".format(plain1.shape, plain1.tolist()))\n",
        "\n",
        "plain2 = ts.plain_tensor(np.array([5,6,7,8]).reshape(2,2))\n",
        "print(\" Second tensor: Shape = {} Data = {}\".format(plain2.shape, plain2.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXSTj0AZnXnI",
        "outputId": "a90f3ddf-8c8d-481c-c78c-fec40e941db8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " First tensor: Shape = [2, 2] Data = [[1.0, 2.0], [3.0, 4.0]]\n",
            " Second tensor: Shape = [2, 2] Data = [[5.0, 6.0], [7.0, 8.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encrypted_tensor1 = ts.ckks_tensor(context, plain1)\n",
        "encrypted_tensor2 = ts.ckks_tensor(context, plain2)\n",
        "\n",
        "print(\" Shape = {}\".format(encrypted_tensor1.shape))\n",
        "print(\" Encrypted Data = {}.\".format(encrypted_tensor1))\n",
        "\n",
        "\n",
        "encrypted_tensor_from_np = ts.ckks_tensor(context, np.array([5,6,7,8]).reshape([2,2]))\n",
        "print(\" Shape = {}\".format(encrypted_tensor_from_np.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n5hujT4nh3A",
        "outputId": "3b5ec564-0533-41d7-85c4-0cbcfd3da85d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape = [2, 2]\n",
            " Encrypted Data = <tenseal.tensors.ckkstensor.CKKSTensor object at 0x7f476a182a50>.\n",
            " Shape = [2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt(enc):\n",
        "    return enc.decrypt().tolist()"
      ],
      "metadata": {
        "id": "0raKNc06nj9v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
        "# Part 2: Evaluation \n",
        "#⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡"
      ],
      "metadata": {
        "id": "wv8v5nsAqm4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BVF Evaluation [ Home-made and TENSEAL]"
      ],
      "metadata": {
        "id": "EEW4AGxpl_VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CKKS Evaluation [ Home-made and TENSEAL]\n",
        "n = 2**4\n",
        "q = 2**15\n",
        "t = 2**8\n",
        "# polynomial modulus\n",
        "poly_mod = np.array([1] + [0] * (n - 1) + [1])\n",
        "# Keygen\n",
        "pk, sk = keygen(n, q, poly_mod)\n",
        "# Encryption\n",
        "pt1, pt2 = 73, 20\n",
        "cst1, cst2 = 7, 5\n",
        "ct1 = encrypt(pk, n, q, t, poly_mod, pt1)\n",
        "ct2 = encrypt(pk, n, q, t, poly_mod, pt2)\n",
        "\n",
        "print(\"[+] Ciphertext ct1({}):\".format(pt1))\n",
        "print(\"\")\n",
        "print(\"\\t ct1_0:\", ct1[0])\n",
        "print(\"\\t ct1_1:\", ct1[1])\n",
        "print(\"\")\n",
        "print(\"[+] Ciphertext ct2({}):\".format(pt2))\n",
        "print(\"\")\n",
        "print(\"\\t ct1_0:\", ct2[0])\n",
        "print(\"\\t ct1_1:\", ct2[1])\n",
        "print(\"\")\n",
        "\n",
        "\"\"\" Multiplication and Addition Evaluation\"\"\"\n",
        "ct3 = add_plain(ct1, cst1, q, t, poly_mod)\n",
        "ct4 = mul_plain(ct2, cst2, q, t, poly_mod)\n",
        "\n",
        "# Decryption\n",
        "decrypted_ct3 = d(sk, n, q, t, poly_mod, ct3)\n",
        "decrypted_ct4 = d(sk, n, q, t, poly_mod, ct4)\n",
        "\n",
        "print(\"[+] Decrypted ct3(ct1 + {}): {}\".format(cst1, decrypted_ct3))\n",
        "print(\"[+] Decrypted ct4(ct2 * {}): {}\".format(cst2, decrypted_ct4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdWlNgWnl95R",
        "outputId": "ad74a77b-7a1a-4ffc-f9e7-f82f15a2e672"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Ciphertext ct1(73):\n",
            "\n",
            "\t ct1_0: [10115 21970 18994 24025 20441 28174 24661 26134 29495 21199 13571 17517\n",
            " 19593 12274 28905 12796]\n",
            "\t ct1_1: [ 6480 31342 17886 11819 18370 21962 24228 23886  2384 18370 25087 25961\n",
            " 30951 20214 30391  2666]\n",
            "\n",
            "[+] Ciphertext ct2(20):\n",
            "\n",
            "\t ct1_0: [28390 22649 31717  2696  5752 28225 16673 31678 27898 16720 12123  5873\n",
            " 16942 12890 22689   503]\n",
            "\t ct1_1: [29489 16884 25280 12577 21457  3265 30557  9813 21504  9955  5165 28757\n",
            " 27989  9659 32554  6466]\n",
            "\n",
            "[+] Decrypted ct3(ct1 + 7): 80\n",
            "[+] Decrypted ct4(ct2 * 5): 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CKKS Evaluation [ CKKS_scratch and TENSEAL]\n"
      ],
      "metadata": {
        "id": "9vD3aURrl4CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CKKS_SCRATCH\n",
        "\"\"\"Addition Evalutaion\"\"\"\n",
        "m1 = np.array([1, 2, 3, 4])\n",
        "m2 = np.array([1, -2, 3, -4])\n",
        "\n",
        "p1 = encoder.sigma_inverse(m1)\n",
        "p2 = encoder.sigma_inverse(m2)\n",
        "\n",
        "p_add = p1 + p2\n",
        "p_add\n",
        "\n",
        "#decode\n",
        "encoder.sigma(p_add)\n",
        "\n",
        "\"\"\"Subtraction Evalutaion\"\"\"\n",
        "p_sub = p1 - p2\n",
        "p_sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 60
        },
        "id": "7DwnVhy2l2vK",
        "outputId": "1cc00602-ebb6-419d-e85a-5cb7d22c2344"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Polynomial([ 3.00000000e+00+7.77156117e-16j,  7.07106781e-01+7.07106781e-01j,\n",
              "       -2.80331314e-15+3.00000000e+00j, -7.07106781e-01+7.07106781e-01j], domain=[-1.,  1.], window=[-1.,  1.])"
            ],
            "text/latex": "$x \\mapsto \\text{(2.9999999999999996+7.771561172376096e-16j)} + (\\text{(0.7071067811865468+0.7071067811865488j)})\\,x + (\\text{(-2.8033131371785203e-15+3.0000000000000004j)})\\,x^{2} + (\\text{(-0.7071067811865483+0.7071067811865455j)})\\,x^{3}$"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CKKS_SCRATCH\n",
        "\"\"\"Multiplication Evalutaion\"\"\"\n",
        "poly_modulo = Polynomial([1,0,0,0,1])\n",
        "poly_modulo\n",
        "p_mult = p1 * p2 % poly_modulo\n",
        "\n",
        "# decode\n",
        "encoder.sigma(p_mult)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eOnpUhTmmzr",
        "outputId": "cc5d7ac7-177a-4381-a9bf-63130de0e270"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.-8.67361738e-16j,  -4.+6.86950496e-16j,   9.+6.86950496e-16j,\n",
              "       -16.-9.08301212e-15j])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CKKS TenSEAL\n",
        "\n",
        "\"\"\"Addition of encrypted tensors\"\"\"\n",
        "result = encrypted_tensor1 + encrypted_tensor2\n",
        "print(\"Plain equivalent: {} + {}\\nDecrypted result: {}.\".format(plain1.tolist(), plain2.tolist(), decrypt(result)))\n",
        "\n",
        "\"\"\"Subtraction of encrypted tensors\"\"\"\n",
        "result = encrypted_tensor1 - encrypted_tensor2\n",
        "print(\"Plain equivalent: {} - {}\\nDecrypted result: {}.\".format(plain1.tolist(), plain2.tolist(), decrypt(result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edjY1F4vnrFy",
        "outputId": "eb698f69-c7db-4b1a-ad58-5020f18f7e05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] + [[5.0, 6.0], [7.0, 8.0]]\n",
            "Decrypted result: [[5.999999999754446, 8.000000000328004], [9.999999999764112, 11.999999999282855]].\n",
            "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] - [[5.0, 6.0], [7.0, 8.0]]\n",
            "Decrypted result: [[-4.0000000003165646, -3.999999999355724], [-3.9999999981057206, -4.000000000232369]].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Multiplication of plain and encrypted tensors\"\"\"\n",
        "result = encrypted_tensor1 * encrypted_tensor2\n",
        "print(\"Plain equivalent: {} * {}\\nDecrypted result: {}.\".format(plain1.tolist(), plain2.tolist(), decrypt(result)))\n",
        "\n",
        "plain = ts.plain_tensor([5,6,7,8], [2,2])\n",
        "result = encrypted_tensor1 * plain\n",
        "\n",
        "print(\"Plain equivalent: {} * {}\\nDecrypted result: {}.\".format(plain1.tolist(), plain.tolist(), decrypt(result)))\n",
        "\n",
        "\"\"\"Polynomial Evaluation\"\"\"\n",
        "result = encrypted_tensor1.polyval([1,0,1,1])\n",
        "\n",
        "print(\"X = {}\".format(plain1.tolist()))\n",
        "print(\"1 + X^2 + X^3 = {}.\".format(decrypt(result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAcXaWJqoRBr",
        "outputId": "9ab4ebe4-7b5d-4754-a0dc-0794862d610b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]]\n",
            "Decrypted result: [[5.000000669396535, 12.000001611929298], [21.00000281933998, 32.00000428730697]].\n",
            "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]]\n",
            "Decrypted result: [[5.000000668846879, 12.000001612334891], [21.000002821622942, 32.000004287436006]].\n",
            "X = [[1.0, 2.0], [3.0, 4.0]]\n",
            "1 + X^2 + X^3 = [[3.00000093796985, 13.000006978908285], [37.00002296061089, 81.0000536172949]].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡ \n",
        "# Part 3: Encrypted Convolution on MNIST\n",
        "#⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡⚡"
      ],
      "metadata": {
        "id": "iA8CaYHIkvxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(73)\n",
        "batch_size = 64\n",
        "\n",
        "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "bj1zbD9B6Srw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "IK1cj6pl6gXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lWK2EYkG6Irx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bb1dd5-357a-4b11-b132-a132656e3d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.397561\n",
            "Epoch: 2 \tTraining Loss: 0.130699\n",
            "Epoch: 3 \tTraining Loss: 0.088399\n",
            "Epoch: 4 \tTraining Loss: 0.071318\n",
            "Epoch: 5 \tTraining Loss: 0.058989\n",
            "Epoch: 6 \tTraining Loss: 0.050542\n",
            "Epoch: 7 \tTraining Loss: 0.044438\n",
            "Epoch: 8 \tTraining Loss: 0.038259\n",
            "Epoch: 9 \tTraining Loss: 0.034644\n",
            "Epoch: 10 \tTraining Loss: 0.030851\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, hidden=64, output=10):\n",
        "        super(ConvNet, self).__init__()        \n",
        "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
        "        self.fc1 = torch.nn.Linear(256, hidden)\n",
        "        self.fc2 = torch.nn.Linear(hidden, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # the model uses the square activation function\n",
        "        x = x * x\n",
        "        # flattening while keeping the batch axis\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.fc1(x)\n",
        "        x = x * x\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
        "    # model in training mode\n",
        "    model.train()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
        "    \n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "model = ConvNet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model = train(model, train_loader, criterion, optimizer, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing\n"
      ],
      "metadata": {
        "id": "bbw96Wjw6igg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    # model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )\n",
        "    \n",
        "test(model, test_loader, criterion)"
      ],
      "metadata": {
        "id": "g2LfufK-6kQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encrypted Evaluation"
      ],
      "metadata": {
        "id": "9kscBWEQ6p3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn\n",
        "!pip install TenSEAL"
      ],
      "metadata": {
        "id": "ePzB3XEB7s2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "It's a PyTorch-like model using operations implemented in TenSEAL.\n",
        "    - .mm() method is doing the vector-matrix multiplication explained above.\n",
        "    - you can use + operator to add a plain vector as a bias.\n",
        "    - .conv2d_im2col() method is doing a single convlution operation.\n",
        "    - .square_() just square the encrypted vector inplace.\n",
        "\"\"\"\n",
        "\n",
        "import tenseal as ts\n",
        "\n",
        "\n",
        "class EncConvNet:\n",
        "    def __init__(self, torch_nn):\n",
        "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
        "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
        "            torch_nn.conv1.kernel_size[1]\n",
        "        ).tolist()\n",
        "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
        "        \n",
        "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
        "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
        "        \n",
        "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
        "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
        "        \n",
        "        \n",
        "    def forward(self, enc_x, windows_nb):\n",
        "        # conv layer\n",
        "        enc_channels = []\n",
        "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
        "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
        "            enc_channels.append(y)\n",
        "        # pack all channels into a single flattened vector\n",
        "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc1 layer\n",
        "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
        "        # square activation\n",
        "        enc_x.square_()\n",
        "        # fc2 layer\n",
        "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
        "        return enc_x\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "metadata": {
        "id": "g1BeB-ZZ6rJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
        "    # initialize lists to monitor test loss and accuracy\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        # Encoding and encryption\n",
        "        x_enc, windows_nb = ts.im2col_encoding(\n",
        "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
        "            kernel_shape[1], stride\n",
        "        )\n",
        "        # Encrypted evaluation\n",
        "        enc_output = enc_model(x_enc, windows_nb)\n",
        "        # Decryption of result\n",
        "        output = enc_output.decrypt()\n",
        "        output = torch.tensor(output).view(1, -1)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "        # calculate test accuracy for each object class\n",
        "        label = target.data[0]\n",
        "        class_correct[label] += correct.item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "\n",
        "    # calculate and print avg test loss\n",
        "    test_loss = test_loss / sum(class_total)\n",
        "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
        "\n",
        "    for label in range(10):\n",
        "        print(\n",
        "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
        "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
        "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
        "    )"
      ],
      "metadata": {
        "id": "wsucBTrR6zmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load one element at a time\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "# required for encoding\n",
        "kernel_shape = model.conv1.kernel_size\n",
        "stride = model.conv1.stride[0]"
      ],
      "metadata": {
        "id": "1Ve2LSzg6t9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encryption Parameters\n",
        "\n",
        "# controls precision of the fractional part\n",
        "bits_scale = 26\n",
        "\n",
        "# Create TenSEAL context\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192,\n",
        "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
        ")\n",
        "\n",
        "# set the scale\n",
        "context.global_scale = pow(2, bits_scale)\n",
        "\n",
        "# galois keys are required to do ciphertext rotations\n",
        "context.generate_galois_keys()"
      ],
      "metadata": {
        "id": "L2nUe3Ei625J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model = EncConvNet(model)"
      ],
      "metadata": {
        "id": "7H_ZXkbG65Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)"
      ],
      "metadata": {
        "id": "aWUxicrFIuuB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}